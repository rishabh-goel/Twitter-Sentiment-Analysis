{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["5iua7quAOlO1","Jv7KCmbVOwq7","FQgNgnH0O3Ij","p_CEC26DB4Ed","rT3KDmE0bHma","I9B-u2N6cxYX","eh0fzuR9fbGF","F_1hjNmFtmR_","pyDl_S0rt0_-"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjZJmy38Ma3T","executionInfo":{"status":"ok","timestamp":1670199098342,"user_tz":360,"elapsed":19437,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"705d7fdb-4fc9-412a-df2a-1e551a51b2a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["import pandas as pd\n","import string\n","import re\n","import numpy as np\n","from collections import Counter\n","import unicodedata\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import spacy\n","from gensim.utils import simple_preprocess\n","from nltk.stem.snowball import SnowballStemmer\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","from collections import defaultdict\n","import pickle\n","import json\n","path = \"/content/drive/My Drive/cs 583/sentiment analysis/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCNrSsHHMnBK","executionInfo":{"status":"ok","timestamp":1670199120050,"user_tz":360,"elapsed":21715,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"4c62a563-13be-40d3-9a1f-6a733907688f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install transformers\n","!pip install evaluate\n","!pip install datasets #restart"],"metadata":{"id":"bx7Z3td4Qp_N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pre-process data: execute once"],"metadata":{"id":"5iua7quAOlO1"}},{"cell_type":"code","source":["dfo = pd.read_csv(path+\"data/Obama.csv\")\n","dfo['candidate']=\"obama\"\n","dfr = pd.read_csv(path+\"data/Romney.csv\")\n","dfr['candidate']='romney'\n","df = pd.concat([dfo,dfr])\n","df.fillna('', inplace = True)\n","print(len(df))\n","df = df.drop_duplicates()\n","print(len(df))\n","df.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"QtCWnDP0Mrle","executionInfo":{"status":"ok","timestamp":1670117530298,"user_tz":360,"elapsed":223,"user":{"displayName":"Rochana Chaturvedi","userId":"12892210805885927021"}},"outputId":"481819f8-c657-4b65-f268-6a2669ceedcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["14398\n","14391\n"]},{"output_type":"execute_result","data":{"text/plain":["       date            time  \\\n","0  10/16/12  10:28:53-05:00   \n","1  12/10/16  10:09:00-05:00   \n","\n","                                               tweet class candidate  \n","0  Kirkpatrick, who wore a baseball cap embroider...     0     obama  \n","1  Question: If <e>Romney</e> and <e>Obama</e> ha...     2     obama  "],"text/html":["\n","  <div id=\"df-1ae38de2-e4be-4214-b578-e222d64305da\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>time</th>\n","      <th>tweet</th>\n","      <th>class</th>\n","      <th>candidate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10/16/12</td>\n","      <td>10:28:53-05:00</td>\n","      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n","      <td>0</td>\n","      <td>obama</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12/10/16</td>\n","      <td>10:09:00-05:00</td>\n","      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n","      <td>2</td>\n","      <td>obama</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ae38de2-e4be-4214-b578-e222d64305da')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ae38de2-e4be-4214-b578-e222d64305da button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ae38de2-e4be-4214-b578-e222d64305da');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def preprocess(example):\n","  new_text = [] \n","  for t in example.split(\" \"):\n","      t = '@user' if t.startswith('@') and len(t) > 1 else t\n","      t = 'http' if t.startswith('http') else t\n","      new_text.append(t)\n","  new_text = \" \".join(new_text)\n","  return new_text"],"metadata":{"id":"KLYCG24ENLY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df['class'].value_counts()) # 0:neutral, 1:positive, -1:negative, 2: mixed\n","df = df[df['class'].isin(['0', '1' , '-1'])]\n","print(len(df))\n","df['class'] = df['class'].astype(int)\n","df = df.rename(columns={'class': 'sentiment'})\n","# print(df.head)\n","df = df.drop(columns=['time', 'date'], axis=1)\n","print(df['sentiment'].value_counts())\n","\n","df['tweet'] = df.tweet.apply(preprocess)\n","df = df[~df.tweet.isna()]\n","df = df[df.tweet!='']\n","print(len(df))\n","# df.to_csv(path+\"data/tweets.csv\")"],"metadata":{"id":"CAOKGye6NDuT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670118002277,"user_tz":360,"elapsed":232,"user":{"displayName":"Rochana Chaturvedi","userId":"12892210805885927021"}},"outputId":"cee39118-73f9-4c0c-d757-fd5057bb78d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-1            4856\n","0             3657\n","2             2895\n","1             2753\n","!!!!           169\n","                34\n","irrevelant      23\n","IR               3\n","irrelevant       1\n","Name: class, dtype: int64\n","11266\n","-1    4856\n"," 0    3657\n"," 1    2753\n","Name: sentiment, dtype: int64\n","11265\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-11-86e0efeacced>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['class'] = df['class'].astype(int)\n"]}]},{"cell_type":"code","source":["df[df.candidate==\"romney\"]['sentiment'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyW6Zr_iySeH","executionInfo":{"status":"ok","timestamp":1670118037166,"user_tz":360,"elapsed":239,"user":{"displayName":"Rochana Chaturvedi","userId":"12892210805885927021"}},"outputId":"eaa85bbe-60ae-47d9-9469-ae58ae290878"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1    2892\n"," 0    1680\n"," 1    1075\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["print(df.head())"],"metadata":{"id":"BuQRD9j_TjvI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Split data for 10 fold Cross validation"],"metadata":{"id":"9HoCo14sPzT8"}},{"cell_type":"code","source":["df = pd.read_csv(path+\"data/tweets.csv\", index_col=None)\n","df.fillna('', inplace = True)\n","df = df.drop('Unnamed: 0', axis=1)\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jhPN_vEpNNZL","executionInfo":{"status":"ok","timestamp":1669768319711,"user_tz":360,"elapsed":456,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"e9bed916-edb2-49eb-be15-64cdec5a5d3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                               tweet  sentiment candidate\n","0  Kirkpatrick, who wore a baseball cap embroider...          0     obama\n","1  #<e>obama</e> debates that Cracker Ass Cracker...          1     obama\n","2  @user @user  Youre missing the point  Im afrai...          0     obama\n","3  I was raised as a Democrat  left the party yea...         -1     obama\n","4  The <e>Obama camp</e> can't afford to lower ex...          0     obama\n"]}]},{"cell_type":"code","source":["df = df[df.tweet!= '']\n","print(df.head(2))\n","strtfdKFold = StratifiedKFold(n_splits=10, shuffle=True)\n","kfold = strtfdKFold.split(df.tweet, df.sentiment)\n","\n","for i, (train, test) in enumerate(kfold):\n","  train_df = df.iloc[train]\n","  test_df = df.iloc[test]\n","  train_df.to_csv(f'{path}data/train/train_{i+1}.csv')\n","  test_df.to_csv(f'{path}data/test/test_{i+1}.csv')\n","  print(f'Iteration {i} done')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"metMaxGmYgOH","executionInfo":{"status":"ok","timestamp":1669768327841,"user_tz":360,"elapsed":1349,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"f0abb89d-ef5e-49e6-dab4-017f22cef468"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                               tweet  sentiment candidate\n","0  Kirkpatrick, who wore a baseball cap embroider...          0     obama\n","1  #<e>obama</e> debates that Cracker Ass Cracker...          1     obama\n","Iteration 0 done\n","Iteration 1 done\n","Iteration 2 done\n","Iteration 3 done\n","Iteration 4 done\n","Iteration 5 done\n","Iteration 6 done\n","Iteration 7 done\n","Iteration 8 done\n","Iteration 9 done\n"]}]},{"cell_type":"markdown","source":["# Vector-space (BOW models)"],"metadata":{"id":"Jv7KCmbVOwq7"}},{"cell_type":"markdown","source":["## Additional pre-processing for BoW models"],"metadata":{"id":"FQgNgnH0O3Ij"}},{"cell_type":"code","source":["#Keep only alphabets\n","def clean_tweet(text):\n","  temp = text.lower()\n","  temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n","  temp = re.sub(\"<[ea]>\",\"\", temp)\n","  temp = re.sub(\"</[ea]>\",\"\",temp)\n","  temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n","  temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n","  temp = re.sub(r'http\\S+', '', temp)\n","  temp = re.sub('[()!?]', ' ', temp)\n","  temp = re.sub('\\[.*?\\]',' ', temp)\n","  temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n","  temp = re.sub(\"[0-9]\", \"\", temp)\n","  temp = re.sub(\"\\</?[a-z]+\\>\", '', temp)\n","  temp = re.sub('\\s+', ' ', temp)\n","  temp = temp.strip()\n","  return temp"],"metadata":{"id":"okOShfRTNiMO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"p_CEC26DB4Ed"}},{"cell_type":"markdown","source":["## Word n-gram"],"metadata":{"id":"GseIf9kCO7ud"}},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"id":"rT3KDmE0bHma"}},{"cell_type":"code","source":["accuracy_list = []\n","precision_list = defaultdict(list)\n","recall_list = defaultdict(list)\n","f1_list = defaultdict(list)\n","\n","for i in range(1, 11):\n","  # train\n","  df_train = pd.read_csv(f'{path}data/train/train_{i}.csv')\n","  df_train['tweet'] = df_train['tweet'].apply(lambda x: clean_tweet(x))\n","  X_train = df_train['tweet']\n","  y_train = df_train['sentiment']\n","  \n","  # test\n","  df_test = pd.read_csv(f'{path}data/test/test_{i}.csv')\n","  df_test['tweet'] = df_test['tweet'].apply(lambda x: clean_tweet(x))\n","  X_test = df_test['tweet']\n","  y_test = df_test['sentiment']\n","  \n","  # vectorizer\n","  vectorizer_word = TfidfVectorizer(max_features=40000, min_df=2, max_df=.5, analyzer='word', stop_words='english', ngram_range=(1, 5))\n","  vectorizer_word.fit(X_train)\n","\n","  # transform & model fit\n","  tfidf_matrix_word_train = vectorizer_word.transform(X_train)\n","  lr_word = LogisticRegression(verbose=2, C=.7, n_jobs = -1, class_weight='balanced')\n","  lr_word.fit(tfidf_matrix_word_train, y_train)\n","  \n","  # save vectorizer \n","  with open(f'{path}vectorizer/LR_Word/LR_Word_vectorizer_{i}.pickle', 'wb') as fin:\n","    pickle.dump(vectorizer_word, fin)\n","\n","  # save model\n","  with open(f'{path}model/LR_Word/LR_Word_{i}.pickle', 'wb') as fin:\n","    pickle.dump(lr_word, fin)\n","\n","  # predict\n","  tfidf_matrix_word_test = vectorizer_word.transform(X_test)\n","  df_test['pred'] = lr_word.predict(tfidf_matrix_word_test)\n","\n","  # save output\n","  df_test.to_csv(f'{path}output/LR_Word/LR_Word_{i}.csv')\n","  \n","  # calculate metrics\n","  report = classification_report(y_test, df_test['pred'], output_dict=True)\n","\n","  # save metrics\n","  with open(f'{path}classification_report/LR_Word/report_{i}.json', \"w\") as outfile:\n","    json.dump(report, outfile)\n","\n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","\n","# display metrics\n","for key, val_list in precision_list.items():\n","  print(f'Avg precision for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in recall_list.items():\n","  print(f'Avg recall for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in f1_list.items():\n","  print(f'Avg f1 for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","print(f'Avg Accuracy: {round(np.mean(accuracy_list), 4)}')\n"],"metadata":{"id":"6LeIJWmVO9ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669950570776,"user_tz":360,"elapsed":62729,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"6df4b03a-9fa4-42cc-c30f-7270c9f5fa67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.4s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.0s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.6s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.7s finished\n"]},{"output_type":"stream","name":"stdout","text":["Avg precision for class -1 = 0.6515 +/- 0.0215\n","Avg precision for class 0 = 0.5276 +/- 0.0186\n","Avg precision for class 1 = 0.5498 +/- 0.0141\n","Avg recall for class -1 = 0.6293 +/- 0.0213\n","Avg recall for class 0 = 0.506 +/- 0.0245\n","Avg recall for class 1 = 0.6124 +/- 0.0261\n","Avg f1 for class -1 = 0.6401 +/- 0.0184\n","Avg f1 for class 0 = 0.5165 +/- 0.0207\n","Avg f1 for class 1 = 0.5793 +/- 0.018\n","Avg Accuracy: 0.5852\n"]}]},{"cell_type":"markdown","source":["## Character n gram"],"metadata":{"id":"I9B-u2N6cxYX"}},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"id":"h5zxPa4wc1WD"}},{"cell_type":"code","source":["accuracy_list = []\n","precision_list = defaultdict(list)\n","recall_list = defaultdict(list)\n","f1_list = defaultdict(list)\n","\n","for i in range(1, 11):\n","  # train\n","  df_train = pd.read_csv(f'{path}data/train/train_{i}.csv')\n","  df_train['tweet'] = df_train['tweet'].apply(lambda x: clean_tweet(x))\n","  X_train = df_train['tweet']\n","  y_train = df_train['sentiment']\n","  \n","  # test\n","  df_test = pd.read_csv(f'{path}data/test/test_{i}.csv')\n","  df_test['tweet'] = df_test['tweet'].apply(lambda x: clean_tweet(x))\n","  X_test = df_test['tweet']\n","  y_test = df_test['sentiment']\n","\n","  # vectorizer\n","  vectorizer_char = TfidfVectorizer(max_features=40000,min_df=5, max_df=0.5, analyzer='char', ngram_range=(1, 11))\n","  vectorizer_char.fit(X_train)\n","\n","  # transform & model fit\n","  tfidf_matrix_char_train = vectorizer_char.transform(X_train)\n","  lr_char = LogisticRegression(verbose=2, C=.7, n_jobs = -1, class_weight='balanced')\n","  lr_char.fit(tfidf_matrix_char_train, y_train)\n","  \n","  # save vectorizer \n","  with open(f'{path}vectorizer/LR_Char/LR_Char_vectorizer_{i}.pickle', 'wb') as fin:\n","    pickle.dump(vectorizer_char, fin)\n","\n","  # save model\n","  with open(f'{path}model/LR_Char/LR_Char_{i}.pickle', 'wb') as fin:\n","    pickle.dump(lr_char, fin)\n","\n","  # predict\n","  tfidf_matrix_char_test = vectorizer_char.transform(X_test)\n","  df_test['pred'] = lr_char.predict(tfidf_matrix_char_test)\n","\n","  # save output\n","  df_test.to_csv(f'{path}output/LR_Char/LR_Char_{i}.csv')\n","  \n","  # calculate metrics\n","  report = classification_report(y_test, df_test['pred'], output_dict=True)\n","\n","  # save metrics\n","  with open(f'{path}classification_report/LR_Char/report_{i}.json', \"w\") as outfile:\n","    json.dump(report, outfile)\n","\n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","\n","# display metrics\n","for key, val_list in precision_list.items():\n","  print(f'Avg precision for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in recall_list.items():\n","  print(f'Avg recall for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in f1_list.items():\n","  print(f'Avg f1 for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","print(f'Avg Accuracy: {round(np.mean(accuracy_list), 4)}')\n"],"metadata":{"id":"WuYlH13Rc1-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669822478294,"user_tz":360,"elapsed":351985,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"9b5b890d-ea32-4bf3-ae31-6f6003dcf065"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    7.8s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.4s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.9s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.3s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.4s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.3s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.3s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.6s finished\n"]},{"output_type":"stream","name":"stdout","text":["Avg precision for class -1 = 0.6513 +/- 0.018\n","Avg precision for class 0 = 0.5389 +/- 0.0191\n","Avg precision for class 1 = 0.5534 +/- 0.0161\n","Avg recall for class -1 = 0.6417 +/- 0.0254\n","Avg recall for class 0 = 0.5134 +/- 0.0224\n","Avg recall for class 1 = 0.6026 +/- 0.0288\n","Avg f1 for class -1 = 0.6463 +/- 0.0204\n","Avg f1 for class 0 = 0.5257 +/- 0.0189\n","Avg f1 for class 1 = 0.5768 +/- 0.0207\n","Avg Accuracy: 0.5905\n"]}]},{"cell_type":"markdown","source":["## Meta-models\n","include obama/romney info"],"metadata":{"id":"eh0fzuR9fbGF"}},{"cell_type":"markdown","source":["### Single model"],"metadata":{"id":"yn-kkPA_ffEj"}},{"cell_type":"code","source":["from scipy import sparse \n","from scipy.sparse import csr_matrix"],"metadata":{"id":"3rHyGa0aff1b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Obama"],"metadata":{"id":"TnQys6bQG_vW"}},{"cell_type":"code","source":["accuracy_list = []\n","precision_list = defaultdict(list)\n","recall_list = defaultdict(list)\n","f1_list = defaultdict(list)\n","\n","for i in range(1, 11):\n","  # train\n","  df_train = pd.read_csv(f'{path}data/train/train_{i}.csv')\n","  df_train['tweet'] = df_train['tweet'].apply(lambda x: clean_tweet(x))\n","  X_train = df_train['tweet']\n","  candidate_train_df = pd.DataFrame({'candidate' : df_train['candidate'] == \"obama\"})\n","  candidate_train = csr_matrix(candidate_train_df)\n","  y_train = df_train['sentiment']\n","\n","  # test\n","  df_test = pd.read_csv(f'{path}data/test/test_{i}.csv')\n","  df_test['tweet'] = df_test['tweet'].apply(lambda x: clean_tweet(x))\n","  X_test = df_test['tweet']\n","  candidate_test_df = pd.DataFrame({'candidate' : df_test['candidate'] == \"obama\"})\n","  candidate_test = csr_matrix(candidate_test_df)\n","  y_test = df_test['sentiment']\n","\n","  # vectorizer\n","  vectorizer_char = TfidfVectorizer(max_features=40000, min_df=5, max_df=0.5, analyzer='char', ngram_range=(1, 11))\n","  vectorizer_char.fit(X_train)\n","\n","  # transform, new X_train & model fit\n","  tfidf_matrix_train = vectorizer_char.transform(X_train)\n","  X_train_new = sparse.hstack((tfidf_matrix_train, candidate_train)).tocsr()\n","  lr_char = LogisticRegression(verbose=2, C=.7, n_jobs = -1, class_weight='balanced')\n","  lr_char.fit(X_train_new, y_train)\n","\n","  # save vectorizer \n","  with open(f'{path}vectorizer/LR_Meta_Single_Char/LR_Meta_Single_Char_vectorizer_{i}.pickle', 'wb') as fin:\n","    pickle.dump(vectorizer_char, fin)\n","\n","  # save model\n","  with open(f'{path}model/LR_Meta_Single_Char/LR_Meta_Single_Char_{i}.pickle', 'wb') as fin:\n","    pickle.dump(lr_char, fin)\n","\n","  # predict\n","  tfidf_matrix_test = vectorizer_char.transform(X_test)\n","  X_test_new = sparse.hstack((tfidf_matrix_test, candidate_test)).tocsr()\n","  df_test['pred'] = lr_char.predict(X_test_new)\n","\n","  # save output\n","  df_test.to_csv(f'{path}output/LR_Meta_Single_Char/LR_Meta_Single_Char_{i}.csv')\n","  \n","  # calculate metrics\n","  report = classification_report(y_test, df_test['pred'], output_dict=True)\n","\n","  # save metrics\n","  with open(f'{path}classification_report/LR_Meta_Single_Char/report_{i}.json', \"w\") as outfile:\n","    json.dump(report, outfile)\n","\n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","\n","# display metrics\n","for key, val_list in precision_list.items():\n","  print(f'Avg precision for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in recall_list.items():\n","  print(f'Avg recall for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in f1_list.items():\n","  print(f'Avg f1 for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","print(f'Avg Accuracy: {round(np.mean(accuracy_list), 4)}')\n"],"metadata":{"id":"ORZ-c_PXfjv6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669822940383,"user_tz":360,"elapsed":363631,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"f61e6d89-bd9e-4229-ee6c-83214ed24330"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.3s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.9s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.2s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    7.6s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.1s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    8.1s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.1s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.3s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.1s finished\n"]},{"output_type":"stream","name":"stdout","text":["Avg precision for class -1 = 0.6527 +/- 0.0185\n","Avg precision for class 0 = 0.5396 +/- 0.019\n","Avg precision for class 1 = 0.5547 +/- 0.015\n","Avg recall for class -1 = 0.6394 +/- 0.0239\n","Avg recall for class 0 = 0.517 +/- 0.0251\n","Avg recall for class 1 = 0.6055 +/- 0.0279\n","Avg f1 for class -1 = 0.6459 +/- 0.0199\n","Avg f1 for class 0 = 0.5279 +/- 0.0204\n","Avg f1 for class 1 = 0.5788 +/- 0.0192\n","Avg Accuracy: 0.5914\n"]}]},{"cell_type":"markdown","source":["### Two models"],"metadata":{"id":"OHyiMVjnHjuF"}},{"cell_type":"code","source":["def predict(row):\n","  if row['candidate']=='obama':\n","    return lr_o.predict(vectorizer_char_o.transform([row['tweet']]))[0]\n","  else:\n","    return lr_r.predict(vectorizer_char_r.transform([row['tweet']]))[0]"],"metadata":{"id":"qjwYJKx3k5FG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_list = []\n","precision_list = defaultdict(list)\n","recall_list = defaultdict(list)\n","f1_list = defaultdict(list)\n","\n","for i in range(1, 11):\n","  # train - obama\n","  df_train= pd.read_csv(f'{path}data/train/train_{i}.csv')\n","  df_train['tweet'] = df_train['tweet'].apply(lambda x: clean_tweet(x))\n","  df_o = df_train[df_train.candidate==\"obama\"]\n","  X_train_o = df_o['tweet']\n","  y_train_o = df_o['sentiment']\n","\n","  # train - romney\n","  df_r = df_train[df_train.candidate==\"romney\"]\n","  X_train_r = df_r['tweet']\n","  y_train_r = df_r['sentiment']\n","\n","  # vectorizer - obama & romney\n","  vectorizer_char_o = TfidfVectorizer(max_features=40000,min_df=5, max_df=0.5, analyzer='char', ngram_range=(1, 11))\n","  vectorizer_char_r = TfidfVectorizer(max_features=40000,min_df=5, max_df=0.5, analyzer='char', ngram_range=(1, 11))\n","  vectorizer_char_o.fit(X_train_o)\n","  vectorizer_char_r.fit(X_train_r)  \n","\n","  # transform & model fit - obama\n","  tfidf_matrix_train_o = vectorizer_char_o.transform(X_train_o)\n","  lr_o = LogisticRegression(verbose=2, C=.7, n_jobs = -1, class_weight='balanced')\n","  lr_o.fit(tfidf_matrix_train_o, y_train_o)\n","\n","  # transform & model fit - romney\n","  tfidf_matrix_train_r = vectorizer_char_r.transform(X_train_r)\n","  lr_r = LogisticRegression(verbose=2, C=.7, n_jobs = -1, class_weight='balanced')\n","  lr_r.fit(tfidf_matrix_train_r, y_train_r)\n","\n","  # save vectorizer \n","  with open(f'{path}vectorizer/LR_Meta_TwoModel_Char/Obama/Obama_{i}.pickle', 'wb') as fin:\n","    pickle.dump(vectorizer_char_o, fin)\n","\n","  with open(f'{path}vectorizer/LR_Meta_TwoModel_Char/Romney/Romney_{i}.pickle', 'wb') as fin:\n","    pickle.dump(vectorizer_char_r, fin)\n","\n","  # save model\n","  with open(f'{path}model/LR_Meta_TwoModel_Char/Obama/Obama_{i}.pickle', 'wb') as fin:\n","    pickle.dump(lr_o, fin)\n","\n","  with open(f'{path}model/LR_Meta_TwoModel_Char/Romney/Romney_{i}.pickle', 'wb') as fin:\n","    pickle.dump(lr_r, fin)\n","\n","  # predict\n","  df_test = pd.read_csv(f'{path}data/test/test_{i}.csv')\n","  df_test['tweet'] = df_test['tweet'].apply(lambda x: clean_tweet(x))\n","  df_test['pred'] = df_test.apply(predict, axis = 1)\n","\n","  # save output\n","  df_test.to_csv(f'{path}output/LR_Meta_TwoModel_Char/LR_Meta_TwoModel_Char_{i}.csv')\n","\n","  # calculate metrics\n","  report = classification_report(df_test['sentiment'], df_test['pred'], output_dict=True)\n","\n","  # save metrics\n","  with open(f'{path}classification_report/LR_Meta_TwoModel_Char/report_{i}.json', \"w\") as outfile:\n","    json.dump(report, outfile)\n","\n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","\n","# display metrics\n","for key, val_list in precision_list.items():\n","  print(f'Avg precision for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in recall_list.items():\n","  print(f'Avg recall for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in f1_list.items():\n","  print(f'Avg f1 for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","print(f'Avg Accuracy: {round(np.mean(accuracy_list), 4)}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAOlMNCxHlTY","executionInfo":{"status":"ok","timestamp":1669823597100,"user_tz":360,"elapsed":404671,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"58c0f698-7c28-476a-8997-5efbcedb8a7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.0s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.2s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.2s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.2s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.9s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.0s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.1s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.3s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.1s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.4s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.9s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.8s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.0s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.9s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.3s finished\n"]},{"output_type":"stream","name":"stdout","text":["Avg precision for class -1 = 0.6472 +/- 0.0128\n","Avg precision for class 0 = 0.5339 +/- 0.021\n","Avg precision for class 1 = 0.5735 +/- 0.016\n","Avg recall for class -1 = 0.6487 +/- 0.0204\n","Avg recall for class 0 = 0.5074 +/- 0.0232\n","Avg recall for class 1 = 0.6088 +/- 0.0229\n","Avg f1 for class -1 = 0.6479 +/- 0.0153\n","Avg f1 for class 0 = 0.5201 +/- 0.0199\n","Avg f1 for class 1 = 0.5906 +/- 0.0186\n","Avg Accuracy: 0.5931\n"]}]},{"cell_type":"markdown","source":["# Transformer-based Language Models"],"metadata":{"id":"Xf0RLnkitQ6D"}},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoTokenizer\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import AutoModelForSequenceClassification\n","from datasets import load_metric\n","from scipy.special import softmax\n","import csv\n","import urllib.request"],"metadata":{"id":"jGSL2vyTtXiv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Roberta twitter sentiment classifier"],"metadata":{"id":"4dmblA4utdWT"}},{"cell_type":"markdown","source":["### Predict w/o fine-tuning"],"metadata":{"id":"F_1hjNmFtmR_"}},{"cell_type":"code","source":["def predict(text):\n","  encoded_input = tokenizer(text, return_tensors='pt')\n","  output = model(**encoded_input)\n","  scores = output[0][0].detach().numpy()\n","  scores = softmax(scores)\n","  \n","  ranking = np.argsort(scores)\n","  ranking = ranking[::-1]\n","  l= labels[ranking[0]]\n","  if l == \"positive\": return 1\n","  elif l == \"negative\":return -1\n","  else: return 0\n","\n","# download label mapping\n","mapping_link = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n","with urllib.request.urlopen(mapping_link) as f:\n","    html = f.read().decode('utf-8').split(\"\\n\")\n","    csvreader = csv.reader(html, delimiter='\\t')\n","labels = [row[1] for row in csvreader if len(row) > 1]#labels are negative, neutral, positive\n","\n","accuracy_list = []\n","precision_list = defaultdict(list)\n","recall_list = defaultdict(list)\n","f1_list = defaultdict(list)\n","MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","\n","for i in range(1, 11):\n","  tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","  model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n","  df_test = pd.read_csv(f'{path}data/test/test_{i}.csv')\n","  x_test = df_test.tweet\n","  y_test = df_test.sentiment\n","\n","  df_test['pred'] = x_test.apply(predict)\n","\n","  # save output\n","  df_test.to_csv(f'{path}output/Roberta_Not_Finetuned/Roberta_Not_Finetuned_{i}.csv')\n","\n","  # calculate metrics\n","  report = classification_report(y_test, df_test['pred'], output_dict=True)\n","\n","  # save metrics\n","  with open(f'{path}classification_report/Roberta_Not_Finetuned/report_{i}.json', \"w\") as outfile:\n","    json.dump(report, outfile)\n","\n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","\n","# display metrics\n","for key, val_list in precision_list.items():\n","  print(f'Avg precision for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in recall_list.items():\n","  print(f'Avg recall for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in f1_list.items():\n","  print(f'Avg f1 for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","print(f'Avg Accuracy = {round(np.mean(accuracy_list), 4)}')\n"],"metadata":{"id":"TSYqlh3dtm5H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Avg precision for class -1 = 0.6803 +/- 0.0147\n","\n","Avg precision for class 0 = 0.4467 +/- 0.0095\n","\n","Avg precision for class 1 = 0.6356 +/- 0.0331\n","\n","Avg recall for class -1 = 0.6534 +/- 0.0092\n","\n","Avg recall for class 0 = 0.6455 +/- 0.0211\n","\n","Avg recall for class 1 = 0.3033 +/- 0.0227\n","\n","Avg f1 for class -1 = 0.6664 +/- 0.0061\n","\n","Avg f1 for class 0 = 0.5279 +/- 0.0116\n","\n","Avg f1 for class 1 = 0.4104 +/- 0.0259\n","\n","Avg Accuracy: 0.5653"],"metadata":{"id":"2r80FiJRDT5n"}},{"cell_type":"markdown","source":["### Finetune Roberta"],"metadata":{"id":"pyDl_S0rt0_-"}},{"cell_type":"code","source":["def transform_labels(label):\n","    label = label['sentiment']\n","    if label == 1:\n","        num = 2\n","    elif label == -1:\n","        num = 0\n","    elif label == 0:\n","        num = 1\n","    return {'labels': num}\n","\n","def tokenize_data(example):\n","    return tokenizer(example['tweet'], padding='max_length', max_length = 512 )"],"metadata":{"id":"SNL_aqU-t3_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","\n","# Training the models\n","for i in range(5, 7):\n","  tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","  dataset = load_dataset('csv', data_files={'train': f'{path}data/train/train_{i}.csv', 'test': f'{path}data/test/test_{i}.csv'}, encoding = \"ISO-8859-1\")\n","  dataset = dataset.map(tokenize_data, batched=True)\n","  model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n","  remove_columns = ['Unnamed: 0', 'tweet', 'sentiment']\n","  dataset = dataset.map(transform_labels, remove_columns=remove_columns)\n","  train_dataset = dataset['train']\n","  eval_dataset = dataset['test']\n","\n","\n","  def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    pred.append(predictions)\n","    y.append(labels)\n","    return metric.compute(predictions=predictions, references=labels, average='macro')\n","\n","  # save training args\n","  training_args = TrainingArguments(f'{path}model/Roberta_Finetuned/Roberta_Checkpoint', num_train_epochs=2)\n","  trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics)\n","  history = trainer.train()\n","\n","  # save model\n","  trainer.save_model(f'{path}model/Roberta_Finetuned/Roberta_Finetuned_{i}')\n","\n","  metric = load_metric(\"f1\", average='macro')\n","  pred =[]\n","  y=[]\n","\n","  # test\n","  trainer.evaluate()\n","\n","  # save output\n","  df = pd.DataFrame({\"pred\":pred[0], \"y\":y[0]})\n","  df['pred'] = df['pred'].replace({0:-1, 1:0, 2:1})\n","  df['y'] = df['y'].replace({0:-1, 1:0, 2:1})\n","  df.to_csv(f'{path}output/Roberta_Finetuned/Roberta_Finetuned_{i}.csv')\n","\n","  # calculate metrics\n","  report = classification_report(df.y, df.pred, output_dict=True)\n","\n","  # save metrics\n","  with open(f'{path}classification_report/Roberta_Finetuned/report_{i}.json', \"w\") as outfile:\n","    json.dump(report, outfile)\n","\n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","  "],"metadata":{"id":"M_ItgBa20YNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_list = []\n","precision_list = defaultdict(list)\n","recall_list = defaultdict(list)\n","f1_list = defaultdict(list)\n","macro_f1 = []"],"metadata":{"id":"iT8HlC6fodTz","executionInfo":{"status":"ok","timestamp":1670199646983,"user_tz":360,"elapsed":154,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import json\n"," \n","# Opening JSON file\n","for i in range(1,11):\n","  with open(f'{path}classification_report/Roberta_Finetuned/report_{i}.json') as json_file:\n","    report = json.load(json_file)\n","  \n","  for index in range(-1, 2):\n","    precision_list[index].append(report[str(index)]['precision'])\n","    recall_list[index].append(report[str(index)]['recall'])\n","    f1_list[index].append(report[str(index)]['f1-score'])\n","  accuracy_list.append(report['accuracy'])\n","  macro_f1.append(report['macro avg']['f1-score'])"],"metadata":{"id":"ugVN2VPHbbSn","executionInfo":{"status":"ok","timestamp":1670199650239,"user_tz":360,"elapsed":1996,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# display metrics\n","f1 = []\n","for key, val_list in precision_list.items():\n","  print(f'Avg precision for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in recall_list.items():\n","  print(f'Avg recall for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","for key, val_list in f1_list.items():\n","  f1.append(round(np.std(val_list), 4))\n","  print(f'Avg f1 for class {key} = {round(np.mean(val_list), 4)} +/- {round(np.std(val_list), 4)}')\n","\n","print(f'Macro f1 : {round(np.mean(macro_f1), 4)} +/- {round(np.std(macro_f1), 4)}')\n","print(f'Avg Accuracy: {round(np.mean(accuracy_list), 4)} +/- {round(np.std(accuracy_list), 4)}')"],"metadata":{"id":"0fsn9naConbD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670199652200,"user_tz":360,"elapsed":139,"user":{"displayName":"Rishabh Goel","userId":"11928585181124320392"}},"outputId":"e6b27d63-6896-452a-af86-ad976f848831"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Avg precision for class -1 = 0.7349 +/- 0.0151\n","Avg precision for class 0 = 0.666 +/- 0.0209\n","Avg precision for class 1 = 0.7206 +/- 0.0169\n","Avg recall for class -1 = 0.8013 +/- 0.0166\n","Avg recall for class 0 = 0.5919 +/- 0.0262\n","Avg recall for class 1 = 0.7109 +/- 0.0257\n","Avg f1 for class -1 = 0.7666 +/- 0.0135\n","Avg f1 for class 0 = 0.6263 +/- 0.0177\n","Avg f1 for class 1 = 0.7154 +/- 0.0163\n","Macro f1 : 0.7028 +/- 0.0116\n","Avg Accuracy: 0.7112 +/- 0.0115\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Bon6lNDXJmzY"},"execution_count":null,"outputs":[]}]}